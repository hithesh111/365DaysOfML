# 365DaysOfML
A commitment to learn ML (and related topics) every day for 365 days starting Jan 1 2023.

## References
1. The Elements of Statistical Learning (ESLR)
2. Serrano.Academy Youtube Channel
3. Ritvik Math Youtube Channel
4. Linkedin Learning
5. 2 Minute Papers Youtube Channel
6. StatQuest Youtube Channel by Josh Starmer
7. Arxiv.org

#### Day 1: ESLR 2.1 to 2.3 

Introduction to Supervised Learning, Variable Types, Encodings, Two Simple Approaches to Prediction: Least Squares and Nearest Neighbors, Other Models as a variant of these two approaches

#### Day 2: ESLR 2.4

Statistical Decision Theory: Probabilistic Setup, Conditional Mean/Median as Regression Function for Squared Loss/Absolute Loss, Linear Model Estimates and Nearest Neighbor Model Estimates from the Regression Function, Solution for Categorical Target Variable, Bayes Classifier.

#### Day 3: ESLR 2.5

Local Methods in High Dimensions: Curse of dimensionality, Nearest Neighbours not really "Near" in Nearest Neighbor models in High Dimensions, Bias-Variance Decomposition of MSE, Linear Assumption (and other Rigid Assumptions) to avoid Curse of Dimensionality.

#### Day 4: ESLR 2.6 to 2.7

Statistical Model for Pr(X,Y), Additive error Model, Supervised Learning, Function Approximation by Least Squares Method and Maximum Likelihood Method, Structured Regression Models: Using implicit or explicit neighborhood restrictions (usually complexity constraints)

#### Day 5: ESLR 2.8

Roughness Penalty or Regularization, Kernel Functions and Local Regression, Basis Functions, Splines, Dictionary Methods (Adaptively Chosen Basis Functions, eg: Neural Networks)

#### Day 6: ESLR 2.9

Model Selection and Bias - Variance Tradeoff, K Nearest Neighbours Example, Test Error, Overfitting and Underfitting

#### Day 7: Serrano.Academy Unsupervised Learning

Gaussian Mixture Models, Iterative Approach to fit a Mixture of Gaussians for Clustering.

#### Day 8: ESLR 3.1, 3.2

Linear Methods of Regression: Introduction, Generalisation and Basis Expansions, Least Square Method of finding Model Coefficients, Normality Assumptions, Significance of Coefficients

#### Day 9: ESLR 3.2.1 to 3.2.4

Significance of Linear Coefficients, Gauss Markov Theorem, Multiple Regression from Univariate Regression, Gram Schmidt Orthogonalisation to find Coefficients, Linear Regression with Multiple Outputs

#### Day 10: ESLR 3.2.1 to 3.2.4

Filling gaps from Day 9

#### Day 11: ESLR 3.3

Subset Selection: Best Subset Selection, Forward and Backward Stepwise Selection, Forward Stagewise Regression

#### Day 12: ESLR 3.4.1 and 3.4.2

Shrinkage Methods: Ridge and Lasso Regression

#### Day 13: ESLR 3.4.3

Comparison of Subset Selection, Ridge Regression and Lasso Regression

#### Day 14: ESLR 3.4.4

Least Angle Regression

#### Day 15 - ESLR 3.4.4

Least Angle Regression

#### Day 16 - ESLR 3.5.1

Methods Using Derived Input Directions: Principal Components Regression

#### Day 17 - https://atmos.washington.edu/~dennis/MatrixCalculus.pdf

Matrix Differentiation Propositions and Proofs.

#### Day 18 - ESLR 3.5.2

Partial Least Squares

#### Day 19 - ESLR 3.6

Comparison of Selection and Shrinkage Methods

#### Day 20 - ESLR 3.7

Multiple Outcome Shrinkage and Selection

#### Day 21 - ESLR 3.7

Multiple Outcome Shrinkage and Selection

#### Day 22 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Learnt about Ranking Models as opposed to Supervised and Unsupervised Models and started off the competition with a naive baseline model submission.

#### Day 23 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Added more logic to predicting the next 'cart' and 'order' item and improved the score.

#### Day 24 - Kaggle Hackathon

OTTO Multi Objective Recommender System: 

#### Day 25 - Serrano.Academy Youtube

How does Netflix recommend movies?

#### Day 26 - Serrano.Academy

KMeans and Heirarchical Clustering

#### Day 27 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Tried Label Propagation method to identify clusters structure to products from browsing order of products.

#### Day 28 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Tried one rule based method of finding key candidates (inferring from the training data) and another method of framing it as a ML problem by creating training data and ranking the probabilities

#### Day 29 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Bug Fixes and Time Optimsiation of the code.

GoDaddy Microbusiness Density Forecasting: Registered for the competition

#### Day 30 - Serrano.Academy

Dirichlet Allocation and Gibbs Sampling

#### Day 31 - Kaggle Hackathon

OTTO Multi Objective Recommender System: Competition Deadline,Final tries

#### Day 32 - Serrano.Academy

Restricted Boltzmann Machines (RBM)

#### Day 33 - Kaggle Hackathon
 
Going through top ranked submissions.

#### Day 34 - ESLR 3.8

Incremental Foreward Stagewise Regression

#### Day 35 - ESLR 3.8

Coding Incremental Foreward Stagewise Regression from Scratch

#### Day 36 - ESLR 3.8

Piecewise Linear Path Algorithms

#### Day 37 - ESLR 3.8

Dantzig Selector

#### Day 38 - ESLR 3.8

Grouped Lasso

#### Day 39 - ESLR 3.8

Further Properties of Lasso

#### Day 40 - ESLR 3.8

Pathwise Coordinate Optimization

#### Day 41 - ESLR 3.9

Computational Considerations 

#### Day 42 - Serrano.Academy

Denoting and Variational Autoencoders

#### Day 43 - Serrano.Academy

Principal Component Analysis

#### Day 44 - ESLR 4.1

Linear Methods for Classification : Introduction

#### Day 45 - ESLR 4.2

Linear Regression of an Indicator Matrix

#### Day 46 - ESLR 4.3

Linear Discriminant Analysis

#### Day 47 - ESLR 4.3.1

Linear Discriminant Analysis: Regularised Discriminant Analysis

#### Day 48 - ESLR 4.3.3

Linear Discriminant Analysis: Reduced Rank Discriminant 

#### Day 49 - ESLR 4.3.2

Linear Discriminant Analysis: Computations for LDA

#### Day 50 - ESLR 4.4

Logistic Regression

#### Day 51 - ESLR 4.4.1

Fitting Logistic Regression Models

#### Day 52 - ESLR 4.4.2

Logistic Regression: South African Heart Disease Example

#### Day 53 - ESLR 4.4.3

Logistic Regression: Quadratic Approximations and Inference

#### Day 54 - Linkedin Learning

Completed the course Transformers: Text Classification for NLP using BERT. 

#### Day 55 - ESLR 4.4.4

L1 Regularized Logistic Regression

#### Day 56 - ESLR 4.4.5

Logistic Regression or LDA?

#### Day 57 - ESLR 4.5

Separating Hyperplanes

#### Day 58 - ESLR 4.5.1

Rosenblatt's Perceptron Learning Algorithm

#### Day 59 - ESLR 4.5.2

Optimal Separating Hyperplanes

#### Day 60 - Luis Serrano.Academy

A Friendly Introduction to Generative Adversarial Networks

#### Day 61 - ESLR 5.1

Basis Expansions and Regularization: Introduction

#### Day 62: ESLR 5.2

Piecewise Polynomials and Splines

#### Day 63: ESLR 5.2.1

Natural Cubic Splines

#### Day 64: ESLR 5.2.2

South African Heart Disease Example

#### Day 65: ESLR 5.2.3

Phoneme Recognition

#### Day 66: ESLR 5.3 - 5.4

Filtering and Feature Extraction, Smoothing Splines

#### Day 67: ESLR 5.4.1

Degrees of Freedom and Smoothing Splines

#### Day 68: ESLR 5.5

Automatic Selection of the Smoothing Parameters

#### Day 69: ESLR 5.5.1

Fixing Degrees of Freedom

#### Day 70: ESLR 5.5.2

Automatic Selection of the Smoothing Parameters: The Bias-Variance Tradeoff

#### Day 71: ESLR 5.6

Non Parametric Logistic Regression 

#### Day 72: ESLR 5.7

Multidimensional Splines

#### Day 73: ESLR 5.8

Regularization and Reproducing Kernel Hilbert Spaces

#### Day 74: ESLR 5.8.1

Spaces of Functions Generated by Kernels 

#### Day 75: ESLR 5.8.2

Examples of RKHS

#### Day 76: ESLR 5.9

Wavelet Smoothing 

#### Day 77: ESLR 5.9.1

Wavelet Bases and Wavelet Transform

#### Day 78: ESLR 5.9.2

Adaptive Wavelet Filtering

#### Day 79: 2 Minute Papers

DALLE-2 for Music Generation

#### Day 80: ESLR 5 - Appendix

Computation for Splines

#### Day 81: ESLR 5 - Appendix

Computation for Smoothing Splines

#### Day 82: ESLR 6

Introduction to Kernel Smoothing Methods

#### Day 83: ESLR 6.1

1 Dimensional Kernel Smoothing

#### Day 84: ESLR 6.1.1

Local Linear Regression

#### Day 85: ESLR 6.1.2

Local Polynomial Regression

#### Day 86: Statquest

Decision Trees, Gini Impurity

#### Day 87: Statquest

Gradient Boost Part 1: Main Regression Ideas

#### Day 88: Statquest

Decision Trees and Pruning

#### Day 89: Statquest

XGBoost for Regression

#### Day 90: 2 Minute Papers

OpenAI GPT4 - The Future is Here

#### Day 91: 2 Minute Papers

Mid journey AI - A League Above DALL-E 2

#### Day 92: 2 Minute Papers

EA's New AI - Next Level Games are Coming

#### Day 93: Statquest

XGBoost for Classification

#### Day 94: Arxiv.org

XGBoost: A Scalable Tree Boosting System

#### Day 95: 2 Minute Papers

DeepMind's AlphaFold AI

#### Day 96: 2 Minute Papers

OpenAI's GPT4

#### Day 97: 2 Minute Papers

Microsoft's new AI clones your voice in 3 seconds 

#### Day 98: 2 Minute Papers

OpenAI's ChatGPT took an IQ test

#### Day 99: ESLR 6.2

Selecting width of a Kernel

#### Day 100: ESLR 6.3

Local Regression in Rp

#### Day 101: ESLR 6.4.1

Structured Kernels

#### Day 102: ESLR 6.4.2

Structured Regression Functions

#### Day 103: ESLR 6.5

Local Likelihood and Other Models

#### Day 104: ESLR 6.6.1

Kernel Density Estimation

#### Day 105: ESLR 6.6.2

Kernel Density Classification

#### Day 106: ESLR 6.6.3

Naive Bayes Classifier

#### Day 107: ESLR 6.7

Radial Basis Functions and Kernels

#### Day 108: 2 Minute Papers

OpenAI's GPT4 - Next Level AI Assistant!

#### Day 109: ESLR 6.8

Mixture Models for Density Estimation and Classification

#### Day 110: 2 Minute Papers

Midjourney AI Version 5

#### Day 111: ESLR 6.9

Computational Considerations

#### Day 112: 2 Minute Papers

NVIDIA's New AI: Better Games are Coming.

#### Day 113: 2 Minute Papers

25 ChatGPT AIs play a game.

#### Day 114: 2 Minute Papers

DeepMind's New AI: 10 Years of Learning in Seconds

### Day 115: 2 Minute Papers

OpenAI's Whisper Learnt 680,000 hours of speech

### Day 116: 2 Minute Papers

Stable Diffusion is getting Outrageously Good

### Day 117: Statquest

Catboost Part 1 : Ordered Target Encoding

### Day 118 - ESLR 7.1

Model Assessment and Selection 

### Day 119 - ESLR 7.2

Bias, Variance and Model Complexity

### Day 120 - ESLR 7.3

The Bias Variance Decomposition

### Day 121 - ESLR 7.3.1

Example: Bias Variance Tradeoff

### Day 122 - ESLR 7.4

Optimism of the training error rate

### Day 123 - ESLR 7.5

Estimates of In-Sample Prediction Error 

### Day 124 - ESLR 7.6

The Effective Number of Parameters

### Day 125 - ESLR 7.7

Bayesian Information Criteria

### Day 126 - ESLR 7.8

Minimum Description Length

### Day 127 - ESLR 7.9

VC Dimension

### Day 128 - ESLR 7.10 - 7.10.2

Cross Validation

### Day 129 - ESLR 7.10.3

Cross Validation 

#### Day 130 - ESLR 7.11

Boostrap Methods

#### Day 131 - ESLR 7.12

Conditional or Expected Test Error

#### Day 132 - ESLR 2.1 - 2.5

Revision of Introduction to Supervised Learning

#### Day 133 - ESLR 2.6 - 2.8

Revision

#### Day 134 - ESLR 8.1

Model Inferencing and Averaging Introduction 

#### Day 135 - ESLR 8.2.1

A Smoothing Example

#### Day 136 - ESLR 8.2.2

Maximum Likelihood Inference

#### Day 137 - ESLR 8.2.3

Bootstrap vs Maximum Likelihood

#### Day 138 - ESLR 8.3

Bayesian methods

#### Day 139 - ESLR 8.4

Relationship between bootstrap and Bayesian inference

#### Day 140 - ESLR 8.5

EM Maximization

#### Day 141 - 2 Minute Papers

Structure and Content Guided Video Synthesis with Diffusion models

#### Day 142 - ESLR 8.5.1

Two component Mixture Model

#### Day 143 - ESLR 8.5.2

The EM Algorithm in General

#### Day 144 - ESLR 8.5.3

EM as Maximization Maximization Procedure

#### Day 145 - ESLR 8.6

MCMC for Sampling from the Posterior

#### Day 146 - ESLR 8.6

Gibbs Sampling for Mixtures

#### Day 147 - ESLR 8.7

Bagging

#### Day 148 - ESLR 8.7.1

Bagging Example: Trees with Simulated Data

#### Day 149 - ESLR 8.8

Model Averaging and Stacking

#### Day 150 - ESLR 8.9

Stochastic Search: Bumping

#### Day 151 - 2 Minute Papers

Google Bard: Is it better than ChatGPT?

#### Day 152 - ESLR 9.1

Generalized Additive Models

#### Day 153 - 2 Minute Papers

DeepMind's AI Athletes Play in the Real World 

#### Day 154 - ESLR 9.1.1

Fitting Additive Models

#### Day 155 - 2 Minute Papers

OpenAI's GPT4 - Eccentric Genius AI

#### Day 156 - ESLR 9.1.2

Example: Additive Regression Model

#### Day 157 - ESLR 9.1.3

Example: Predicting Email Spam

#### Day 158 - ESLR 9.1.3

Summary of Additive Regression Model

#### Day 159 - ESLR 9.2.1

Tree Based Methods: Background

#### Day 160 - ESLR 9.2

Tree Based Methods: Classification Trees, Regression Trees and Other Issues

#### Day 161 - ESLR 9.3

Patient Rule Induction Method

Tree Based Methods: Classification Trees, Regression Trees and Other Issues
